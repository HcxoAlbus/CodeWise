"""
RAGçŸ¥è¯†åº“æ£€ç´¢å·¥å…·
è´Ÿè´£äººï¼šç»„å‘˜B
ä½œç”¨ï¼šå°è£…å‘é‡æ•°æ®åº“æ£€ç´¢åŠŸèƒ½ä¸ºLangChain Toolï¼Œæä¾›ä»£ç ä¼˜åŒ–å’Œæœ€ä½³å®è·µå»ºè®®
"""

import logging
import os
from typing import List, Dict, Any
from langchain.tools import BaseTool
# ä¿®å¤ LangChain å¯¼å…¥è­¦å‘Š
try:
    from langchain_community.vectorstores import FAISS
    from langchain_community.embeddings import HuggingFaceEmbeddings
except ImportError:
    # å¦‚æœæ–°ç‰ˆæœ¬å¯¼å…¥å¤±è´¥ï¼Œä½¿ç”¨æ—§ç‰ˆæœ¬å¯¼å…¥
    from langchain.vectorstores import FAISS
    from langchain.embeddings import HuggingFaceEmbeddings

from langchain.schema import Document
import numpy as np

from config.settings import get_settings

logger = logging.getLogger(__name__)
settings = get_settings()


class RAGTool(BaseTool):
    """RAGçŸ¥è¯†åº“æ£€ç´¢å·¥å…·ç±»"""
    
    name: str = "knowledge_retriever"
    description: str = """
    ä»Pythonç¼–ç¨‹çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³çš„æœ€ä½³å®è·µã€ä¼˜åŒ–å»ºè®®å’Œä»£ç ç¤ºä¾‹ã€‚
    è¾“å…¥ï¼šä»£ç ç‰‡æ®µæˆ–ç¼–ç¨‹æ¦‚å¿µå…³é”®è¯
    è¾“å‡ºï¼šç›¸å…³çš„çŸ¥è¯†åº“å†…å®¹ï¼ŒåŒ…æ‹¬æœ€ä½³å®è·µå’Œä¼˜åŒ–å»ºè®®
    """
    
    def __init__(self):
        super().__init__()
        self.embeddings = None
        self.vector_store = None
        self._init_rag_system()
    
    def _init_rag_system(self):
        """åˆå§‹åŒ–RAGç³»ç»Ÿ"""
        try:
            # åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
            self.embeddings = HuggingFaceEmbeddings(
                model_name="sentence-transformers/all-MiniLM-L6-v2",
                model_kwargs={'device': 'cpu'}
            )
            
            # å°è¯•åŠ è½½ç°æœ‰çš„å‘é‡æ•°æ®åº“
            vector_db_path = settings.vector_db_path
            if os.path.exists(vector_db_path):
                self.vector_store = FAISS.load_local(
                    vector_db_path, 
                    self.embeddings,
                    allow_dangerous_deserialization=True
                )
                logger.info("å·²åŠ è½½ç°æœ‰å‘é‡æ•°æ®åº“")
            else:
                # åˆ›å»ºæ–°çš„å‘é‡æ•°æ®åº“
                self._create_initial_knowledge_base()
                logger.info("å·²åˆ›å»ºæ–°çš„å‘é‡æ•°æ®åº“")
                
        except Exception as e:
            logger.error(f"RAGç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {str(e)}")
            self.vector_store = None
    
    def _create_initial_knowledge_base(self):
        """åˆ›å»ºåˆå§‹çŸ¥è¯†åº“"""
        try:
            # åŸºç¡€Pythonæœ€ä½³å®è·µæ–‡æ¡£
            documents = [
                Document(
                    page_content="ä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼ä»£æ›¿ä¼ ç»Ÿå¾ªç¯å¯ä»¥æé«˜ä»£ç æ€§èƒ½å’Œå¯è¯»æ€§ã€‚ä¾‹å¦‚ï¼š[x*2 for x in range(10)] æ¯”ä½¿ç”¨forå¾ªç¯æ›´åŠ Pythonicã€‚",
                    metadata={"topic": "åˆ—è¡¨æ¨å¯¼å¼", "category": "æ€§èƒ½ä¼˜åŒ–"}
                ),
                Document(
                    page_content="ä½¿ç”¨withè¯­å¥è¿›è¡Œæ–‡ä»¶æ“ä½œå¯ä»¥ç¡®ä¿æ–‡ä»¶æ­£ç¡®å…³é—­ï¼Œé¿å…èµ„æºæ³„æ¼ã€‚ä¾‹å¦‚ï¼šwith open('file.txt', 'r') as f: content = f.read()",
                    metadata={"topic": "æ–‡ä»¶æ“ä½œ", "category": "æœ€ä½³å®è·µ"}
                ),
                Document(
                    page_content="é¿å…åœ¨å¾ªç¯ä¸­ä½¿ç”¨å­—ç¬¦ä¸²æ‹¼æ¥ï¼Œä½¿ç”¨join()æ–¹æ³•æˆ–f-stringä¼šæ›´é«˜æ•ˆã€‚ä¾‹å¦‚ï¼š''.join(items) æˆ– f'{name}_{id}'",
                    metadata={"topic": "å­—ç¬¦ä¸²æ“ä½œ", "category": "æ€§èƒ½ä¼˜åŒ–"}
                ),
                Document(
                    page_content="ä½¿ç”¨isinstance()è€Œä¸æ˜¯type()è¿›è¡Œç±»å‹æ£€æŸ¥ï¼Œè¿™æ ·å¯ä»¥æ­£ç¡®å¤„ç†ç»§æ‰¿å…³ç³»ã€‚ä¾‹å¦‚ï¼šisinstance(obj, str) è€Œä¸æ˜¯ type(obj) == str",
                    metadata={"topic": "ç±»å‹æ£€æŸ¥", "category": "æœ€ä½³å®è·µ"}
                ),
                Document(
                    page_content="å‡½æ•°åº”è¯¥éµå¾ªå•ä¸€èŒè´£åŸåˆ™ï¼Œæ¯ä¸ªå‡½æ•°åªåšä¸€ä»¶äº‹ã€‚å¤æ‚çš„å‡½æ•°åº”è¯¥æ‹†åˆ†ä¸ºå¤šä¸ªå°å‡½æ•°ã€‚",
                    metadata={"topic": "å‡½æ•°è®¾è®¡", "category": "ä»£ç ç»“æ„"}
                ),
                Document(
                    page_content="ä½¿ç”¨å¼‚å¸¸å¤„ç†æ—¶è¦æ•è·å…·ä½“çš„å¼‚å¸¸ç±»å‹ï¼Œé¿å…ä½¿ç”¨è£¸éœ²çš„exceptè¯­å¥ã€‚ä¾‹å¦‚ï¼šexcept ValueError: è€Œä¸æ˜¯ except:",
                    metadata={"topic": "å¼‚å¸¸å¤„ç†", "category": "æœ€ä½³å®è·µ"}
                ),
                Document(
                    page_content="ä½¿ç”¨ç”Ÿæˆå™¨è¡¨è¾¾å¼å¤„ç†å¤§æ•°æ®é›†å¯ä»¥èŠ‚çœå†…å­˜ã€‚ä¾‹å¦‚ï¼šsum(x*x for x in range(1000000))",
                    metadata={"topic": "ç”Ÿæˆå™¨", "category": "å†…å­˜ä¼˜åŒ–"}
                ),
                Document(
                    page_content="ç±»çš„å‘½ååº”è¯¥ä½¿ç”¨å¸•æ–¯å¡å‘½åæ³•(PascalCase)ï¼Œå‡½æ•°å’Œå˜é‡ä½¿ç”¨è›‡å½¢å‘½åæ³•(snake_case)ã€‚",
                    metadata={"topic": "å‘½åè§„èŒƒ", "category": "ä»£ç é£æ ¼"}
                )
            ]
            
            # åˆ›å»ºå‘é‡å­˜å‚¨
            self.vector_store = FAISS.from_documents(documents, self.embeddings)
            
            # ä¿å­˜å‘é‡æ•°æ®åº“
            os.makedirs(os.path.dirname(settings.vector_db_path), exist_ok=True)
            self.vector_store.save_local(settings.vector_db_path)
            
        except Exception as e:
            logger.error(f"åˆ›å»ºçŸ¥è¯†åº“å¤±è´¥: {str(e)}")
            raise
    
    def _run(self, query: str) -> str:
        """
        æ£€ç´¢ç›¸å…³çŸ¥è¯†
        
        Args:
            query: æŸ¥è¯¢å†…å®¹ï¼ˆä»£ç ç‰‡æ®µæˆ–å…³é”®è¯ï¼‰
            
        Returns:
            ç›¸å…³çš„çŸ¥è¯†åº“å†…å®¹
        """
        try:
            if not self.vector_store:
                return "âŒ çŸ¥è¯†åº“æœªåˆå§‹åŒ–"
            
            # æ‰§è¡Œç›¸ä¼¼åº¦æœç´¢
            docs = self.vector_store.similarity_search(
                query, 
                k=3  # è¿”å›æœ€ç›¸å…³çš„3ä¸ªç»“æœ
            )
            
            if not docs:
                return "ğŸ’¡ æœªæ‰¾åˆ°ç›¸å…³çš„æœ€ä½³å®è·µå»ºè®®"
            
            # æ ¼å¼åŒ–æ£€ç´¢ç»“æœ
            return self._format_retrieval_results(docs)
            
        except Exception as e:
            logger.error(f"çŸ¥è¯†åº“æ£€ç´¢å¤±è´¥: {str(e)}")
            return f"âŒ æ£€ç´¢è¿‡ç¨‹å‡ºé”™: {str(e)}"
    
    async def _arun(self, query: str) -> str:
        """å¼‚æ­¥ç‰ˆæœ¬çš„è¿è¡Œæ–¹æ³•"""
        return self._run(query)
    
    def _format_retrieval_results(self, docs: List[Document]) -> str:
        """
        æ ¼å¼åŒ–æ£€ç´¢ç»“æœ
        
        Args:
            docs: æ£€ç´¢åˆ°çš„æ–‡æ¡£åˆ—è¡¨
            
        Returns:
            æ ¼å¼åŒ–çš„çŸ¥è¯†åº“å†…å®¹
        """
        if not docs:
            return "ğŸ’¡ æœªæ‰¾åˆ°ç›¸å…³å»ºè®®"
        
        result = "ğŸ“š ä»çŸ¥è¯†åº“ä¸­æ‰¾åˆ°ä»¥ä¸‹ç›¸å…³å»ºè®®ï¼š\n\n"
        
        for i, doc in enumerate(docs, 1):
            metadata = doc.metadata
            topic = metadata.get('topic', 'æœªçŸ¥ä¸»é¢˜')
            category = metadata.get('category', 'å…¶ä»–')
            
            result += f"ğŸ”¸ å»ºè®® {i} - {topic} ({category}):\n"
            result += f"   {doc.page_content}\n\n"
        
        result += "ğŸ’¡ å»ºè®®æ ¹æ®ä»¥ä¸Šæœ€ä½³å®è·µä¼˜åŒ–æ‚¨çš„ä»£ç ã€‚"
        
        return result
    
    def add_knowledge(self, content: str, topic: str, category: str = "å…¶ä»–"):
        """
        å‘çŸ¥è¯†åº“æ·»åŠ æ–°å†…å®¹
        
        Args:
            content: çŸ¥è¯†å†…å®¹
            topic: ä¸»é¢˜
            category: åˆ†ç±»
        """
        try:
            if not self.vector_store:
                logger.error("å‘é‡å­˜å‚¨æœªåˆå§‹åŒ–")
                return False
            
            doc = Document(
                page_content=content,
                metadata={"topic": topic, "category": category}
            )
            
            # æ·»åŠ åˆ°å‘é‡å­˜å‚¨
            self.vector_store.add_documents([doc])
            
            # ä¿å­˜æ›´æ–°
            self.vector_store.save_local(settings.vector_db_path)
            
            logger.info(f"å·²æ·»åŠ æ–°çŸ¥è¯†: {topic}")
            return True
            
        except Exception as e:
            logger.error(f"æ·»åŠ çŸ¥è¯†å¤±è´¥: {str(e)}")
            return False
    
    def get_knowledge_stats(self) -> Dict[str, Any]:
        """è·å–çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯"""
        try:
            if not self.vector_store:
                return {"status": "æœªåˆå§‹åŒ–", "count": 0}
            
            # è·å–å‘é‡æ•°é‡ï¼ˆç®€åŒ–çš„ç»Ÿè®¡ï¼‰
            index_size = self.vector_store.index.ntotal if hasattr(self.vector_store, 'index') else 0
            
            return {
                "status": "å¯ç”¨",
                "document_count": index_size,
                "embedding_model": "all-MiniLM-L6-v2"
            }
            
        except Exception as e:
            logger.error(f"è·å–çŸ¥è¯†åº“ç»Ÿè®¡å¤±è´¥: {str(e)}")
            return {"status": "é”™è¯¯", "error": str(e)}


def get_rag_tool() -> RAGTool:
    """è·å–RAGå·¥å…·å®ä¾‹"""
    return RAGTool()